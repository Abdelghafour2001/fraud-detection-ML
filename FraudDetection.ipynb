{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neo4j\n",
      "  Using cached neo4j-4.4.3.tar.gz (90 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\abdel\\anaconda3\\lib\\site-packages (from neo4j) (2021.3)\n",
      "Building wheels for collected packages: neo4j\n",
      "  Building wheel for neo4j (setup.py): started\n",
      "  Building wheel for neo4j (setup.py): finished with status 'done'\n",
      "  Created wheel for neo4j: filename=neo4j-4.4.3-py3-none-any.whl size=116068 sha256=2d3dfe567a8eb43010a7fd6940f043ff93e5757e1f3a0fafe2d6d7c810b5f69e\n",
      "  Stored in directory: c:\\users\\abdel\\appdata\\local\\pip\\cache\\wheels\\a0\\8c\\08\\e5396fee5c4d6c2e7901c049aad7aec428eafe2d752565019c\n",
      "Successfully built neo4j\n",
      "Installing collected packages: neo4j\n",
      "Successfully installed neo4j-4.4.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"0000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "driver = GraphDatabase.driver(url, auth=(user, password))\n",
    "neo4j = driver.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "result = neo4j.run('MATCH (c1:Customer)-[:PERFORMS]->(t1:Transaction)-[:WITH]->(m1:Merchant) Where t1.fraud=\"1\" RETURN c1.id')\n",
    "df = pd.DataFrame(result.data())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "MATCH (c1:Customer)-[:PERFORMS]->(t1:Transaction)-[:WITH]->(m1:Merchant)\n",
    "WITH c1, m1\n",
    "MERGE (p1:Placeholder {id: m1.id})\n",
    "\"\"\")\n",
    "print(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "MATCH (c1:Customer)-[:PERFORMS]->(t1:Transaction)-[:WITH]->(m1:Merchant)\n",
    "WITH c1, m1, count(*) as cnt\n",
    "MERGE (p2:Placeholder {id:c1.id})\n",
    "\"\"\")\n",
    "print(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "MATCH (c1:Customer)-[:PERFORMS]->(t1:Transaction)-[:WITH]->(m1:Merchant)\n",
    "WITH c1, m1, count(*) as cnt\n",
    "MATCH (p1:Placeholder {id:m1.id})\n",
    "WITH c1, m1, p1, cnt\n",
    "MATCH (p2:Placeholder {id: c1.id})\n",
    "WITH c1, m1, p1, p2, cnt\n",
    "CREATE (p2)-[:PAYS {cnt: cnt}]->(p1)\n",
    "\"\"\")\n",
    "print(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "MATCH (c1:Customer)-[:PERFORMS]->(t1:Transaction)-[:WITH]->(m1:Merchant)\n",
    "WITH c1, m1, count(*) as cnt\n",
    "MATCH (p1:Placeholder {id:c1.id})\n",
    "WITH c1, m1, p1, cnt\n",
    "MATCH (p2:Placeholder {id: m1.id})\n",
    "WITH c1, m1, p1, p2, cnt\n",
    "CREATE (p1)-[:PAYS {cnt: cnt}]->(p2)\n",
    "\"\"\")\n",
    "print(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Cypher query\n",
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.graph.create.cypher.estimate(\n",
    "    'MATCH (p) WHERE p:Placeholder RETURN id(p) as id',\n",
    "    'MATCH (p)-[i:PAYS]->(p1:Placeholder) RETURN id(p) AS source, id(p1) AS target')\n",
    "\"\"\")\n",
    "\n",
    "# Print the results\n",
    "row = result.single()\n",
    "print(\"Estimated:\", row['nodeCount'], \"nodes,\", row['relationshipCount'], \"relationships,\", row['requiredMemory'],\" memory required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint \n",
    "\n",
    "# This query drops the projected graph if it already exists, else it returns 'None'.\n",
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.graph.exists($name) YIELD exists\n",
    "WHERE exists\n",
    "CALL gds.graph.drop($name) YIELD graphName\n",
    "RETURN graphName + \" was dropped.\" as message\n",
    "\"\"\", name = 'pageRank')\n",
    "\n",
    "# Print the results\n",
    "pprint.pprint(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.graph.create.cypher(\n",
    "    'pageRank',\n",
    "    'MATCH (p) WHERE p:Placeholder RETURN id(p) as id',\n",
    "    'MATCH (p)-[h:PAYS]->(p1:Placeholder) RETURN id(p) AS source, h.cnt as weight, id(p1) AS target')\n",
    "\"\"\")\n",
    "\n",
    "# Print the results\n",
    "row = result.single()\n",
    "print(row['graphName'],\"-\", row['nodeCount'], \"nodes,\", row['relationshipCount'], \"relationships,\", row['createMillis'],\" ms to create the projection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.pageRank.stream.estimate('pageRank',  { relationshipWeightProperty: 'weight' })\n",
    "\"\"\")\n",
    "\n",
    "print(result.single()['requiredMemory'], ' memory required to run the algorithm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "CALL gds.pageRank.stream('pageRank', { relationshipWeightProperty: 'weight'}) \n",
    "YIELD nodeId, score\n",
    "RETURN gds.util.asNode(nodeId).id as id, score \n",
    "ORDER BY score DESC\n",
    "\"\"\")\n",
    "\n",
    "df = pd.DataFrame(result.data())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j.run(\"CALL gds.pageRank.write('pageRank', { writeProperty: 'pageRank', relationshipWeightProperty: 'weight' })\")\n",
    "\n",
    "pprint.pprint(result.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = neo4j.run(\"\"\"MATCH (p:Placeholder)\n",
    "RETURN p.id AS id, p.pageRank as pagerank\n",
    "\"\"\")\n",
    "\n",
    "df = pd.DataFrame(result.data())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from py2neo import Graph\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pagerank(record):\n",
    "    return records[record.split(\"'\")[1]]['pagerank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_df = pd.read_csv(\"bs140513_032310.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = bank_df['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id    pagerank\n",
      "0      M348934600  183.568446\n",
      "1     M1823072687  241.650932\n",
      "2       M50039827    3.020985\n",
      "3     M1888755466    1.753567\n",
      "4     M1053599405    5.738430\n",
      "...           ...         ...\n",
      "4157  C2060410910    0.150000\n",
      "4158  C1657671280    0.150000\n",
      "4159  C1743702978    0.150000\n",
      "4160   C849065220    0.150000\n",
      "4161  C1562081159    0.150000\n",
      "\n",
      "[4162 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result = neo4j.run(\"\"\"\n",
    "MATCH (p:Placeholder)\n",
    "RETURN p.id AS id, p.pageRank as pagerank\n",
    "\"\"\")\n",
    "\n",
    "df= pd.DataFrame(result.data())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id          |           pagerank \r\n",
      "-------------|--------------------\r\n",
      " M348934600  | 183.56844635009764 \r\n",
      " M1823072687 | 241.65093231201172 \r\n",
      " M50039827   | 3.0209848880767822 \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = Graph(password=\"0000\")\n",
    "\n",
    "# Query to fetch the network features from Neo4j\n",
    "query = \"\"\"\n",
    "MATCH (p:Placeholder)\n",
    "RETURN p.id AS id, p.pageRank as pagerank\n",
    "\"\"\"\n",
    "\n",
    "data = graph.run(query)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {}\n",
    "\n",
    "for record in data:\n",
    "    records[record['id']] = { 'pagerank': record['pagerank']}\n",
    "\n",
    "# Merging the graph features with the banksim dataset\n",
    "\n",
    "bank_df['merchant_pagerank'] = bank_df['merchant'].apply(load_pagerank)\n",
    "bank_df['customer_pagerank'] = bank_df['customer'].apply(load_pagerank)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        step       customer  age gender zipcodeOri       merchant zipMerchant  \\\n",
      "0          0  'C1093826151'  '4'    'M'    '28007'   'M348934600'     '28007'   \n",
      "1          0   'C352968107'  '2'    'M'    '28007'   'M348934600'     '28007'   \n",
      "2          0  'C2054744914'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
      "3          0  'C1760612790'  '3'    'M'    '28007'   'M348934600'     '28007'   \n",
      "4          0   'C757503768'  '5'    'M'    '28007'   'M348934600'     '28007'   \n",
      "...      ...            ...  ...    ...        ...            ...         ...   \n",
      "594638   179  'C1753498738'  '3'    'F'    '28007'  'M1823072687'     '28007'   \n",
      "594639   179   'C650108285'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
      "594640   179   'C123623130'  '2'    'F'    '28007'   'M349281107'     '28007'   \n",
      "594641   179  'C1499363341'  '5'    'M'    '28007'  'M1823072687'     '28007'   \n",
      "594642   179   'C616528518'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
      "\n",
      "                   category  amount  fraud  merchant_pagerank  \\\n",
      "0       'es_transportation'    4.55      0         183.568446   \n",
      "1       'es_transportation'   39.68      0         183.568446   \n",
      "2       'es_transportation'   26.89      0         241.650932   \n",
      "3       'es_transportation'   17.25      0         183.568446   \n",
      "4       'es_transportation'   35.72      0         183.568446   \n",
      "...                     ...     ...    ...                ...   \n",
      "594638  'es_transportation'   20.53      0         241.650932   \n",
      "594639  'es_transportation'   50.73      0         241.650932   \n",
      "594640         'es_fashion'   22.44      0           2.484065   \n",
      "594641  'es_transportation'   14.46      0         241.650932   \n",
      "594642  'es_transportation'   26.93      0         241.650932   \n",
      "\n",
      "        customer_pagerank  \n",
      "0                    0.15  \n",
      "1                    0.15  \n",
      "2                    0.15  \n",
      "3                    0.15  \n",
      "4                    0.15  \n",
      "...                   ...  \n",
      "594638               0.15  \n",
      "594639               0.15  \n",
      "594640               0.15  \n",
      "594641               0.15  \n",
      "594642               0.15  \n",
      "\n",
      "[594643 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(bank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unnecessary columns including the age and gender attributes\n",
    "feature_df = bank_df.drop(['step', 'age', 'gender', 'customer', 'zipcodeOri', 'zipMerchant', 'fraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding the categorical variables\n",
    "feature_df = pd.get_dummies(feature_df, columns=['category', 'merchant'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "standard_scaler = StandardScaler()\n",
    "scaled_df = pd.DataFrame(standard_scaler.fit_transform(feature_df), columns = feature_df.columns)\n",
    "\n",
    "scaled_df = scaled_df.values\n",
    "labels = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "random_forest = RandomForestClassifier(max_depth=20, n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building Random Forest classifier with k=5 folds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    117489\n",
      "           1       0.77      0.75      0.76      1440\n",
      "\n",
      "    accuracy                           0.99    118929\n",
      "   macro avg       0.88      0.87      0.88    118929\n",
      "weighted avg       0.99      0.99      0.99    118929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    117489\n",
      "           1       0.85      0.75      0.79      1440\n",
      "\n",
      "    accuracy                           1.00    118929\n",
      "   macro avg       0.92      0.87      0.90    118929\n",
      "weighted avg       1.00      1.00      1.00    118929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    117489\n",
      "           1       0.88      0.74      0.81      1440\n",
      "\n",
      "    accuracy                           1.00    118929\n",
      "   macro avg       0.94      0.87      0.90    118929\n",
      "weighted avg       1.00      1.00      1.00    118929\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    117488\n",
      "           1       0.92      0.73      0.81      1440\n",
      "\n",
      "    accuracy                           1.00    118928\n",
      "   macro avg       0.96      0.86      0.91    118928\n",
      "weighted avg       1.00      1.00      1.00    118928\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    117488\n",
      "           1       0.94      0.70      0.81      1440\n",
      "\n",
      "    accuracy                           1.00    118928\n",
      "   macro avg       0.97      0.85      0.90    118928\n",
      "weighted avg       1.00      1.00      1.00    118928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nBuilding Random Forest classifier with k=5 folds\")\n",
    "for train_index, test_index in k_fold.split(scaled_df, labels):\n",
    "\n",
    "    X_train, X_test = scaled_df[train_index], scaled_df[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "    clf = random_forest.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(random_forest, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17640/2032374474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test,predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
